{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12958048",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4330e6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statistics import mode\n",
    "import shutil\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd4cf35",
   "metadata": {},
   "source": [
    "# I - Création des tfrecord train et test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b4d88d8",
   "metadata": {},
   "source": [
    "## 1 - paramètres :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e4c451b",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_od_csv = '/tf/ship_detect_tl/data_parsing/CSV/train_ship_segmentations_OD.csv'\n",
    "path_h_csv = '/tf/ship_detect_tl/data_parsing/CSV/boats_hash.csv'\n",
    "path_cluster_csv = '/tf/ship_detect_tl/data_parsing/CSV/clusters_sizes.csv'\n",
    "path_images = '/tf/ship_data/train_v2'\n",
    "boat_rate = 0.7 # taux d'images contenant au moins un bateau\n",
    "cut_rate = 0.8 # taux d'images (par rapport à nb_images) utilisées pour train. Le reste sera utilisé pour test.\n",
    "tfrecord_dir = '/tf/ship_data/annotations' # répertoire où train et test seront créés"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f410913",
   "metadata": {},
   "source": [
    "## 2 - exécution du script :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab7debc",
   "metadata": {},
   "source": [
    "Génère deux fichiers au format tfrecord dans le répertoire tfrecord_dir : deux fichiers train et test nommés selon train_70_80.tfrecord pour 70% d'images avec bateau réparties 80% dans train, le reste dans test.\n",
    "Génère également"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ad18862",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/tf/ship_detect_tl/train_test_split/clusters_sizes.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgenerate_tfrecord\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m generate_tf_record\n\u001b[0;32m----> 2\u001b[0m \u001b[43mgenerate_tf_record\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_od_csv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath_h_csv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath_cluster_csv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcut_rate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mboat_rate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtfrecord_dir\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/tf/ship_detect_tl/scripts/generate_tfrecord.py:109\u001b[0m, in \u001b[0;36mgenerate_tf_record\u001b[0;34m(path_od_csv, path_h_csv, path_cluster_csv, cut_rate, boat_rate, tfrecord_dir, only_one)\u001b[0m\n\u001b[1;32m    104\u001b[0m df_test \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(columns\u001b[38;5;241m=\u001b[39mdf_od\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mtolist())\n\u001b[1;32m    106\u001b[0m     \u001b[38;5;66;03m# on crée deux listes de noms d'images : une correspondant à la base d'entrainement et l'autre à la base de test.\u001b[39;00m\n\u001b[1;32m    107\u001b[0m     \u001b[38;5;66;03m# idée du fonctionnement : on remplie d'abord ces deux listes avec les noms d'images contenant des bateaux, puis avec le noms des images vides. Enfin, on mélange les listes ainsi crées.\u001b[39;00m\n\u001b[0;32m--> 109\u001b[0m df_clust \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_cluster_csv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    110\u001b[0m df_red \u001b[38;5;241m=\u001b[39m df_clust\u001b[38;5;241m.\u001b[39mdrop(\u001b[38;5;241m2\u001b[39m) \u001b[38;5;66;03m# on supprime le cluster numéro 2 parce qu'il contient 5929 bateaux alors que le 2ème plus gros cluster n'en contient que 126, ce qui complique l'échantillonage stratifié\u001b[39;00m\n\u001b[1;32m    112\u001b[0m         \u001b[38;5;66;03m# on crée de nouvelles colonnes au dataframe en subdivisant W_mean, H_mean et n_boats en *bins* catégories \u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/util/_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[1;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[1;32m    310\u001b[0m     )\n\u001b[0;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py:680\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    665\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    666\u001b[0m     dialect,\n\u001b[1;32m    667\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    676\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m    677\u001b[0m )\n\u001b[1;32m    678\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 680\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py:575\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    572\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    574\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 575\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    577\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    578\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py:933\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    930\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    932\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 933\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py:1217\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1213\u001b[0m     mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1214\u001b[0m \u001b[38;5;66;03m# error: No overload variant of \"get_handle\" matches argument types\u001b[39;00m\n\u001b[1;32m   1215\u001b[0m \u001b[38;5;66;03m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[39;00m\n\u001b[1;32m   1216\u001b[0m \u001b[38;5;66;03m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[39;00m\n\u001b[0;32m-> 1217\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[call-overload]\u001b[39;49;00m\n\u001b[1;32m   1218\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1219\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1220\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1221\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1222\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1223\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1224\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1225\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1226\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1227\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1228\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/common.py:789\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    784\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    785\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    786\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    787\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    788\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 789\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    790\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    791\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    792\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    796\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    797\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    798\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/tf/ship_detect_tl/train_test_split/clusters_sizes.csv'"
     ]
    }
   ],
   "source": [
    "from generate_tfrecord import generate_tf_record\n",
    "generate_tf_record(path_od_csv, path_h_csv, path_cluster_csv, cut_rate, boat_rate, tfrecord_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "510f6520",
   "metadata": {},
   "source": [
    "# II - Chargement du modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddacd9a1",
   "metadata": {},
   "source": [
    "## 1 - paramètres :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fbacc48",
   "metadata": {},
   "source": [
    "Les modèles sont importés du \"model zoo\" de tensorflow : https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2_detection_zoo.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c260b7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_dir = '/tf/pretrained_models' # répertoire où les models seront téléchargés\n",
    "model_url = 'http://download.tensorflow.org/models/object_detection/tf2/20200711/mask_rcnn_inception_resnet_v2_1024x1024_coco17_gpu-8.tar.gz'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea8b49c",
   "metadata": {},
   "source": [
    "## 2 - exécution du script :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ea4792f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from http://download.tensorflow.org/models/object_detection/tf2/20200711/mask_rcnn_inception_resnet_v2_1024x1024_coco17_gpu-8.tar.gz\n",
      "484548608/484546405 [==============================] - 9s 0us/step\n"
     ]
    }
   ],
   "source": [
    "from download_model import download_model\n",
    "download_model(model_url, models_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "882993dd",
   "metadata": {},
   "source": [
    "# III - Paramétrage des hyperparamètres du modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09177970",
   "metadata": {},
   "source": [
    "Le paramétrage suivant n'est pas exhaustif. Seuls les paramètres génériques, assurant à l'apprentissage puisse être lancé. D'autres hyperparamètres spécifiques au modèle choisi (generations des \"anchor boxes\" par exemple) doivent également être paramétrés."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa84424f",
   "metadata": {},
   "source": [
    "##  1 - Lister des bases train et test disponibles, choix des paramètres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f7150cad",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tf/ship_data/annotations/test_50_80_70.tfrecord\n",
      "/tf/ship_data/annotations/train_25_80_70.tfrecord\n",
      "/tf/ship_data/annotations/train_100_80_70.tfrecord\n",
      "/tf/ship_data/annotations/test_100_80_70.tfrecord\n",
      "/tf/ship_data/annotations/train_1_80_70.tfrecord\n",
      "/tf/ship_data/annotations/test_1_80_70.tfrecord\n",
      "/tf/ship_data/annotations/train_50_80_70.tfrecord\n",
      "/tf/ship_data/annotations/test_25_80_70.tfrecord\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "for path in [os.path.join(tfrecord_dir, p) for p in os.listdir(tfrecord_dir)]:\n",
    "    print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2dda8c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_dict = {\n",
    "    'num_classes' : 1,\n",
    "    'batch_size' : 48,\n",
    "    'train_tfrecord_path' : '/tf/ship_data/annotations/70_80_masks/train_70_80.tfrecord',\n",
    "    'test_tfrecord_path' : '/tf/ship_data/annotations/70_80_masks/test_70_80.tfrecord',\n",
    "    'label_map_path' : '/tf/ship_detect_tl/data/label_map.txt',\n",
    "    'fine_tune_checkpoint' : '/tf/pretrained_models/checkpoints/mask_rcnn_inception_resnet_v2_1024x1024_coco17_gpu-8/checkpoint/ckpt-0',\n",
    "    'fine_tune_checkpoint_type' : \"detection\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7246a9cc",
   "metadata": {},
   "source": [
    "## 2 -  Ecrire ces paramètres dans le fichier config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "70570fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_config_path = '/tf/custom_models/mask_rcnn_inception_resnet_v2_1024x1024_coco17_gpu-8/pipeline.config'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7ed39d52",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing pipeline config file to /tf/custom_models/mask_rcnn_inception_resnet_v2_1024x1024_coco17_gpu-8/pipeline.config\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[07/21 06:51:29] tensorflow INFO: Writing pipeline config file to /tf/custom_models/mask_rcnn_inception_resnet_v2_1024x1024_coco17_gpu-8/pipeline.config\n"
     ]
    }
   ],
   "source": [
    "from modify_pipeline import modify_pipeline\n",
    "modify_pipeline(pipeline_config_path, config_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e3ac13",
   "metadata": {},
   "source": [
    "# IV - Génération des commandes pour lancer l'entrainement et l'évaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e777b08",
   "metadata": {},
   "source": [
    "Il s'agira de copier ses commandes et de les coller dans le terminal de la machine où l'on souhaite lancer l'entrainement. \n",
    "Autrement dit, ces commandes doivent être exécutées dans le container paramétré selon la procédure décrite *EXPLIQUER OÙ*.\n",
    "Ensuite, pour pouvoir avoir deux courbes (entrainement et validation), il faut exécuter les commande d'entrainement et de test en parallèle dans deux terminaux (dans le container). De plus, il est nécéssaire de veiller à allouer les ressources GPU de sorte que le calcul de la validation soit terminé avant l'arrivée du prochain checkpoint (on peut aussi jouer sur d'autres paramètres tels que la taille du dataset test, le nombre de steps avant d'écrire un checkpoint ou encore le nombre d'images testées dans le dataset test)/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "883842a8",
   "metadata": {},
   "source": [
    "## 1 -  Entrainement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64520571",
   "metadata": {},
   "source": [
    "### Allocation des ressources GPU (voir paragraphe précédent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b44f89",
   "metadata": {},
   "source": [
    "Dans le terminal du container dans lequel sera exécuté l'entrainement, coller (ex. si l'on choisit les GPU 0,1 et 2) : export CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6509ac1e",
   "metadata": {},
   "source": [
    "### Commande pour l'entrainement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4943aa0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = '/tf/custom_models/mask_rcnn_inception_resnet_v2_1024x1024_coco17_gpu-8/checkpoint'\n",
    "pipeline_config_path = '/tf/custom_models/mask_rcnn_inception_resnet_v2_1024x1024_coco17_gpu-8/pipeline.config'\n",
    "num_train_steps = '25000'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "720f147c",
   "metadata": {},
   "source": [
    "Copier coller la commande affichée après exécution de la cellule suivante dans le terminal du container dans lequel sera exécuté l'entrainement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "743a0f79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python /tf/models/research/object_detection/model_main_tf2.py --model_dir=/tf/custom_models/mask_rcnn_inception_resnet_v2_1024x1024_coco17_gpu-8/checkpoint --pipeline_config_path=/tf/custom_models/mask_rcnn_inception_resnet_v2_1024x1024_coco17_gpu-8/pipeline.config --num_train_steps=25000 --alsologtostderr\n"
     ]
    }
   ],
   "source": [
    "command = 'python /tf/models/research/object_detection/model_main_tf2.py --model_dir={} --pipeline_config_path={} --num_train_steps={} --alsologtostderr'.format(model_dir, pipeline_config_path, num_train_steps)\n",
    "print(command)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2764fd3a",
   "metadata": {},
   "source": [
    "## 2 -  Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "125a3c0f",
   "metadata": {},
   "source": [
    "### Allocation des ressources GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "435919cd",
   "metadata": {},
   "source": [
    "Dans le terminal du container dans lequel sera exécuté l'entrainement, coller (ex. si l'on choisit les GPU 3) : export CUDA_VISIBLE_DEVICES=7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a3ab7d9",
   "metadata": {},
   "source": [
    "### Commande pour la validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "84320bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = model_dir\n",
    "sample_1_of_n_eval_examples = '1'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1e4b94e",
   "metadata": {},
   "source": [
    "Copier coller la commande affichée après exécution de la cellule suivante dans le terminal du container dans lequel sera exécuté l'entrainement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d3795f3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python /tf/models/research/object_detection/model_main_tf2.py --model_dir=/tf/custom_models/mask_rcnn_inception_resnet_v2_1024x1024_coco17_gpu-8/checkpoint --pipeline_config_path=/tf/custom_models/mask_rcnn_inception_resnet_v2_1024x1024_coco17_gpu-8/pipeline.config --checkpoint_dir=/tf/custom_models/mask_rcnn_inception_resnet_v2_1024x1024_coco17_gpu-8/checkpoint --sample_1_of_n_eval_examples=1\n"
     ]
    }
   ],
   "source": [
    "command = 'python /tf/models/research/object_detection/model_main_tf2.py --model_dir={} --pipeline_config_path={} --checkpoint_dir={} --sample_1_of_n_eval_examples={}'.format(model_dir, pipeline_config_path, checkpoint_dir, sample_1_of_n_eval_examples)\n",
    "print(command)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "559c2b38",
   "metadata": {},
   "source": [
    "# V - observation des résultats "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d6e7f2",
   "metadata": {},
   "source": [
    "Les courbes sont observables sous Tensorboard. Pour le lancer, il faudra exécuter la commande suivante dans le terminal du container. Puisque Tensorboard va tourner sur l'adresse locale du container, il ne sera pas accessible depuis l'ordinateur hôte. Il faut mettre en place du port forwarding voir établir un tunnel ssh si le container tourne sur un server. Cependant, pas d'inquiétude ! Si le container est ouvert sur VSCode, ce dernier va s'en occuper pour nous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b19e4dd2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorboard --logdir /tf/custom_models/faster_rcnn_resnet101_v1_640x640_coco17_tpu-8/checkpoint --host 0.0.0.0\n"
     ]
    }
   ],
   "source": [
    "print('tensorboard --logdir {} --host 0.0.0.0'.format(model_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b91b97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd28ad2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
